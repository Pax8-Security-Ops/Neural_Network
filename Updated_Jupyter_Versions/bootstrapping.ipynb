{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0680ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'Dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     20\u001b[0m rawDataFrame\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# np.unique(rawDataFrame[\"Dataset\"], return_counts=True)             # Convert the dataset into an array and point out what unique data points are in the assigned\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# unique_values, value_counts = np.unique(rawDataFrame[\"Dataset\"], return_counts=True)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# unique_values, value_counts = np.unique(rawDataFrame[\"Dataset\"].values, return_counts=True)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m unique_values, value_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(rawDataFrame\u001b[38;5;241m.\u001b[39mDataset, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m1= Bad Data (Malware; abnormal traffic)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m2= Good Data (Normal Traffic; clean files)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     36\u001b[0m badData \u001b[38;5;241m=\u001b[39m rawDataFrame\u001b[38;5;241m.\u001b[39mloc[rawDataFrame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]           \u001b[38;5;66;03m# Arrange all data points labeled with the Dataset point of '1'\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'Dataset'"
     ]
    }
   ],
   "source": [
    "import numpy                                                       # Using python to accomadate order of operations and numerical functions\n",
    "import pandas                                                      # For reading files and depicting imported data\n",
    "import random                                                      # Using python tools to generate random integers and outcomes\n",
    "import sys                                                         # Add the ability to import tools and files inside the container's directories\n",
    "sys.path.insert(0, '/home')                                        # Import the home directory into python's file path so the files and programs therein are reachable\n",
    "import matplotlib.pyplot as plt                                    # Allow visualization of graphical interfaces\n",
    "\n",
    "get_ipython().run_line_magic('run', '~/universalComponents/activation.ipynb')\n",
    "# get_ipython().run_line_magic('run', '~/universalComponents/layer.ipynb')\n",
    "# get_ipython().run_line_magic('run', '~/universalComponents/network.ipynb')\n",
    "\n",
    "\n",
    "# from ml.universalComponents import network as net                  # Import the pre-made code to create neural nets into this notebook\n",
    "# from ml.universalComponents import layer as lyr                    # Allow the creation and organization of layer components of which data will be fed through the neural net\n",
    "# from ml.universalComponents import activation as act_fun           # Make the function to execute the neural net usable on this notebook\n",
    "\n",
    "\n",
    "rawDataFrame = (\"Filename_containing_data\")                        # Import the entire dataset as a whole with no edits\"\n",
    "\n",
    "rawDataFrame\n",
    "\n",
    "# np.unique(rawDataFrame[\"Dataset\"], return_counts=True)             # Convert the dataset into an array and point out what unique data points are in the assigned\n",
    "\n",
    "# unique_values, value_counts = np.unique(rawDataFrame[\"Dataset\"], return_counts=True)\n",
    "\n",
    "# unique_values, value_counts = np.unique(rawDataFrame[\"Dataset\"].values, return_counts=True)\n",
    "\n",
    "unique_values, value_counts = np.unique(rawDataFrame.Dataset, return_counts=True)\n",
    "\n",
    "\n",
    "'''\n",
    "1= Bad Data (Malware; abnormal traffic)\n",
    "2= Good Data (Normal Traffic; clean files)\n",
    "'''\n",
    "\n",
    "badData = rawDataFrame.loc[rawDataFrame['Dataset'] == 1]           # Arrange all data points labeled with the Dataset point of '1'\n",
    "badData.iloc()                                                     # Seperate the date points from the overall set to create a sample\n",
    "badData  # Display the sample\"\n",
    "\n",
    "goodData = rawDataFrame.loc[rawDataFrame['Dataset'] == 2]          # Arrange all data points labeled with the dataset point of '2'\n",
    "goodData.iloc()                                                    # Seperate the data points from the overall set to create a new sample\n",
    "goodData # Display the sample\n",
    "\n",
    "badData.iloc[chart_position: ]                                     # Extract data points starting from position 75 and downward of the SickLiver set and display the final result\n",
    "goodData.loc[chart_position: ]                                     # Extract data points starting from position 25 and downward of the HealthLiver set and display the final result\n",
    "\n",
    "Features = rawDataFrame = [[\"\"]]                                   # List all desired data categories to be listed\n",
    "Target = rawDataFrame = [[\"Dataset\"]]                              # Arrange the data points to abide by the previously stated dataset definitions: 1=Good, 2=Bad\n",
    "\n",
    "X_Train  = Features.iloc[:int(len(Features) * .9)]                 # Extracting 90% of all listed data points from the 'Features' columns to be sent through a neural net\n",
    "Y_Train = Target.iloc[:int(len(Features) * .9)]                    # Extracting 90 % of all listed data points from the 'Features' rows to be sent through a neural net\n",
    "\n",
    "X_Test = Features.iloc[:int(len(Features) * .9) : ]                # Extracting 90% of all listed data points from the 'Features' columns to evaluate the performance of the neural net following the training phase\n",
    "Y_Test = Target.iloc[:int(len(Features) * .9) : ]                  # Extracting 90% of all listed datapoints from the 'Features' rows to evaluate the performance of the neural net following the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909701ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b1d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa1b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
